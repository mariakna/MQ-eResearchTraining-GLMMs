---
title: "Data analysis using (generalised) linear mixed effects models in R"
author: "Maria Korochkina"
date: "Last update: `r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    toc: yes
    toc_depth: 5
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    theme: cerulean
fontsize: 16pt
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

# Load required packages

```{r, results = "hide"}
rm(list=ls())

library("openxlsx")
library("Rmisc")
library("tidyverse")
library("lme4")
library("car")
library("MASS")
library("scales")
library("lmerTest")
library("sjmisc")
library("sjPlot")
library("ggsignif")
library("RColorBrewer")
```

# Load data

Data that we will be using today is publicly available [here](https://github.com/mariakna/MQ-eResearchTraning--G-LMEmodels).

Download the file *pwiExp.xlsx*, save it in a directory of your choice, make this directory your working directory by using the command `setwd()` and load the file as shown below:

```{r}
data <- read.xlsx("pwiExp.xlsx", sheet = 1)
```

## Data description

This file contains data from a picture-word interference task. In this task, German native speakers named (in German) pictures of familiar concepts (e.g., elephant) with superimposed written word distractors. The distractors were either semantically related (e.g., 'cat') or unrelated (e.g.'hammer') to the depicted concepts. The distractors were (a) German words, (b) novel words that the participants had learned earlier, or (c) unknown pseudowords. 

<center>
![FigName](pwi.png){width=300px}
</center>

The data we just loaded contains the following information (only relevant columns explained):

- `Subj`: Participant ID (there were 60 participants in total)
- `List`: Which list the participant received (1-5)
- `ItemType`: Experimental or filler (this file only contains experimental items)
- `Cond`: Condition. This a factor with 5 levels: `SemRelG` (semantically related German), `SemUnRelG` (semantically unrelated German), `SemRelN` (semantically related novel), `SemUnRelN` (semantically unrelated novel), `Baseline` (unknown pseudowords as distractors)
- `TargetCat`: semantic category of the depicted concept (target)
- `DistCat`: semantic category of the distractor
- `Dist`: distractor word
- `DistLC`: Learning context of the distractor: `Fam` stands for German word, `Untrained` stands for unknown pseudowords, `CRel` stands for catgeorically related, `UnRel` stands for categorically unrelated (more on that later)
- `TargetAnswer`: correct picture name (in German)
- `Response`: participant's response
- `Accuracy`: `0` for incorrect responses, `1` for correct responses
- `RT`: response times

<style>
div.blue{background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

**Hypotheses 1 & 2:**

- Compared to semantically unrelated German distractors, German distractors from the same semantic category will slow picture naming response times
- Compared to unknown pseudowords, German semantically unrelated distractors will slow picture naming response times

</div>
<p>  </p>

Because our first two hypotheses only concern German and unknown pseudoword distractors, we will restrict the dataset:

```{r}
data2 <- data %>%
  filter(Cond == "SemRelG" | Cond == "SemUnRelG" | Cond == "Baseline")
```

Next, adjust factor levels for the independent variable and random terms:

```{r}
data2$Cond <- factor(data2$Cond)
levels(data2$Cond)

data2$Subj <- factor(data2$Subj)
data2$TargetAnswer <- factor(data2$TargetAnswer)
```

# Inspect data

This step is essential and should not be neglected as it allows you to ensure that your data looks as it should. You can do it in any way you want. I often used the function `xtabs()`, for example:

```{r}
head(xtabs(~ Subj + List,data2)) 
head(xtabs(~ Subj + Cond,data2)) 
xtabs(~ List + Cond,data2) 
xtabs(~ Cond + DistLC,data2) 
xtabs(~ List + DistLC,data2) 
```

# Prepare data for analysis

## Remove incorrect responses

We will run our analysis on correct responses only so we first need to check accuracy and exclude observations with incorrect responses.

Let's look at overall accuracy first:

```{r}
ftable(data2$Accuracy)
```

And now accuracy per condition:

```{r}
(Accuracy <- summarySEwithin(data2, measurevar = "Accuracy", withinvars = "Cond",
                       idvar = "Subj", na.rm = FALSE, conf.interval = .95))
```

**Note:** The function `summarySEwithin` is a good (although not yet widely accepted) method to summarise data for experiments with a within-subjects design. The standard SE formula

$$
\sigma_{\overline{x}} = \frac{s}{\sqrt{n}}
$$

does  not take into  account  that there are multiple  data  points  from  each  participant  and, instead,  summarises  the  variability  across  all  observations  as  if  they  were  independent. Similarly, aggregating the data and calculating averages per participant per condition would conflate variability associated with each participantâ€™s performance and random error with the variability  associated  with  the  experimental  manipulation. One method  to  compute  standard error while also disentangling these two sources of variability was described in [Morey (2008)](http://pcl.missouri.edu/sites/default/files/morey.2008.pdf) and later implemented in the [Rmisc package](http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/) in R by Ryan Hope. 

Luckily, the participants are at ceiling! We can now restrict the data to correct responses:

```{r}
dataCorr <- data2 %>%
  filter(Accuracy == 1)
```

## Data trimming

There are many ways to do it, and it often depends on your research question and your knowledge about the processes you are studying. For example, in word production, it often makes sense to remove data points with super fast and super slow responses. 

I quite like the approach of keeping as many observations as you can and trying to model them so I often start with inspecting the data distribution and only removing those data points that clearly stand out:

```{r}
plot(density(dataCorr$RT))
```

Based on the data distribution and what we know about picture naming, we remove responses faster than 300ms and slower than 2000ms. 

```{r}
dataCorr2 <- dataCorr %>%
 filter(RT > 300 & RT < 2000) # 12 obs removed
```

# Contrast coding

<style>
div.blue{background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

**Hypotheses 1 & 2:**

- Compared to semantically unrelated German distractors, German distractors from the same semantic category will slow picture naming response times
- Compared to unknown pseudowords, German semantically unrelated distractors will slow picture naming response times

</div>
<p>  </p>

How can we test these hypotheses?

1. We could fit two separate models, one testing the first hypothesis (contrast between semantically related and unrelated distractors) and the other testing the second hypothesis (contrast between semantically unrelated and uknown pseudoword distractors)

2. We could fit one model testing both hypotheses (and contrasts) simultaneously.

Whatever we choose, we need to code the specified contrasts first. Understanding of contrast coding is essential, and I will now show you why.

## Option 1: Treatment vs. sum contrasts for a factor with 2 levels

Imagine we opt for option 1 and restrict our dataset to data points with semantically related and unrelated distractors:

```{r}
dataOpt1 <- dataCorr2 %>%
  filter(Cond == "SemRelG" | Cond == "SemUnRelG")
```

Don't forget to adjust the levels of `Cond`:

```{r}
levels(dataOpt1$Cond) # Baseline is still included
dataOpt1$Cond <- factor(dataOpt1$Cond)
levels(dataOpt1$Cond) # Baseline is no longer there
```


Now imagine we do not know anything about contrast coding and we simply fit the model without giving it much thought (don't worry about not including random terms at the moment:

```{r}
model1 <- lm(RT ~ Cond, data = dataOpt1)

round(summary(model1)$coef,3)
```

How does R arrive at these particular values for the intercept and slope? We can find this out by inspecting the current contrasts of the factor `Cond` using the `contrasts()` command:

```{r}
contrasts(dataOpt1$Cond)
```

The default in R, often called **dummy coding**, is to code factors using treatment contrasts, whereby factor levels are ordered alphabetically. That's why level `SemRelG` is coded as 0 and level `SemUnRelG` is coded as 1. 

Now, what does that mean for our model?

$$
RT \sim \beta_0 + \beta_1*Cond 
$$ 

- Intercept $\beta_0$ is the estimated value (RT) for `SemRelG` 
- Slope $\beta_1$ is the estimated difference between the means of the two levels (i.e., `SemUnRelG`-`SemRelG`). The sign of the slope is negative because RTs are slower in `SemRelG`

$$
RT_{Related} = 847 - 0*27 = 847\\
RT_{Unrelated} = 847 - 1*27  = 820
$$ 

From a theoretical point of view, the intercept in the treatment assesses the average response in the baseline condition (in this case, in the semantically related condition), while the slope tests the difference between condition means. This also means that the intercept expresses a null hypothesis that is of no interest to us: that the mean in condition `SemRelG` is 0:

$$
H_0: \beta_0 = 0\\
H_0: \mu_{Unrelated} - \mu_{Related} = 0
$$

This contrast coding does not reflect the comparisons we would like to make and so does not correspond to the theoretical knowledge about how cognitive processes work. Therefore, it is better to use  **sum contast coding** instead:

```{r}
dataOpt1$Condition <- ifelse(dataOpt1$Cond == "SemRelG", -1, 1)

# we can also do:
contrasts(dataOpt1$Cond) <- c(-1,+1)
contrasts(dataOpt1$Cond)
```

Now, `SemRelG` is coded as -1 and `SemUnRelG` is coded as 1. What do the intercept and the slope represent now?

```{r}
model2 <- lm(RT ~ Cond, data = dataOpt1)

round(summary(model2)$coef,3)
```

- Intercept $\beta_0$ is now the estimated mean of the two conditions
- Slope $\beta_1$ is still the estimated difference between the means of the two conditions (i.e., `SemUnRelG`-`SemRelG`)

$$
RT_{GrandMean} = 834 - 0*14 = 834\\
RT_{Unrelated} = 834 - 1*14  = 820\\
RT_{Related} = 834 + 1*14  = 848\\
$$
Importantly, while the slope still assesses the difference in condition means, the intercept now tests the null hypothesis that the average of the two conditions is 0:

$$
H_0: \frac{\mu_{Unrelated} + \mu_{Related}}{2} = 0\\
H_0: \mu_{Unrelated} - \mu_{Related} = 0
$$
To summarise,

<style>
div.blue{background-color:#e6f0ff; border-radius: 5px; padding: 20px;}
</style>
<div class = "blue">

- Treatment contrasts compare one or more means against some (arbitrarily chosen by default in R) baseline condition.
- Sum contrasts compare a condition's mean against the grand mean. If we only have two conditions, this basically tests whether the two condition's means are identical.

</div>
<p>  </p>

## Option 2: Sum contrasts for a factor with 3 levels

Let us now think how we can test the two contrats (related vs. unrelated, and unrelated vs. unknown) in one model.

Basically, we want to code the factor `Cond` in such a way so that, for the first comparison, it contrasts the semantically related condition with the semantically unrelated condition while it disregards the unknown pseudoword condition, and, for the second comparison, it contrasts the unrelated condition with the unknown condition while ignoring the related condition.

Contrast 1:

$$
H_0: \mu_{Unrelated} - \mu_{Related} = 0
$$
Contrast 2:

$$
H_0: \mu_{Unrelated} - \mu_{Unknown} = 0
$$

And the null hypothesis for the intercept:

\begin{align}

H_0 &= \frac{\mu_{Unrelated} + \mu_{Related} + \mu_{Unknown}}{3} \\
&= \frac{1}{3} \mu_{Unrelated} + \frac{1}{3} \mu_{Related} + \frac{1}{3} \mu_{Unknown} \\
&= 0

\end{align}

We can summarise this as follows:

| Cond      | Contrast 1  | Contrast 2  | Intercept |
|-----------|-------------|-------------|-----------|
| SemRelG   | 1           | 0           | 1/3       |
| SemUnRelG | -1          | -1          | 1/3       |
| Baseline  | 0           | 0           | 1/3       |

and store this in a **hypothesis matrix**:

```{r}
(fractions(t(matrix <- rbind(int = 1/3, 
                       c1 = c(Baseline = 0, SemRelG = 1, SemUnRelG = -1),
                       c2 = c(Baseline = 1, SemRelG = 0, SemUnRelG = -1)))))
```

To obtain a contrast matrix necessary to test these hypotheses in a linear model, this matrix has to be inverted (see [Friendly, Fox & Chalmers, 2018](https://cran.r-project.org/web/packages/matlib/vignettes/ginv.html) and [Schad et al., 2019](https://arxiv.org/abs/1807.10451) for more detail):

```{r}
# function that formats the output of ginv():
ginv2 <- function(x)
 fractions(provideDimnames(ginv(x), base = dimnames(x)[2:1]))

# Invert matrix:
(matrix2 <- ginv2(matrix))
# Assign matrix to variable Cond:
(contrasts(dataCorr2$Cond) <- matrix2[, 2:3])
```

Now we only need to adjust the dataset to be able to convert from a factor-based random-effects structure to a vector-valued one:

```{r}
m0 <- lmer(RT ~ Cond + (1 + Cond||Subj) + (1 + Cond||TargetAnswer), data = dataCorr2)

mat <- model.matrix(m0)
dataCorr2$SemRel.SemUnRel <- mat[, 2]
dataCorr2$Bas.SemUnRel <- mat[, 3]

dataCorr2[1:5,18:ncol(dataCorr2)]
```

# Transform or not transform?

The core assumptions of the linear mixed effects models is that the residuals and random effect coefficients are independent and identically distributed. Ideally, the residuals should be normally distributed, and, if this assumption is violated, the model cannot be interpreted.


```{r}
m1 <- lm(RT ~ Cond, data = dataCorr2)
hist(residuals(m1))
qqPlot(residuals(m1))
```

A quantile-quntile (QQ) plot is a scatterplot, in which two sets of quantiles are plotted against each other. If both sets of quantiles came from the same distribution, the points should form a straight line. By default, `qqplot()` produces a normal QQ plot and so allows us to check whether the model residuals are normally distributed (you can also use `qqnorm()`).

It would seem that the model residuals have more extreme values than would be expected if they were normally distributed.

How can we deal with that? There are 2 options:

- transfrom the data such that it satisfies the model assumptions
- use generalised linear mixed effects models with a different (not normal) distribution

There is a lot of controversy about which approach is best. If interested, you can take a look at [Lo & Andrews, 2015](https://www.frontiersin.org/articles/10.3389/fpsyg.2015.01171/full), [Donnelly & Verkuilen, 2017](https://www.sciencedirect.com/science/article/pii/S0749596X1630167X), [Pierre et al., 2018](https://onlinelibrary.wiley.com/doi/full/10.1002/ece3.3807), [De Boeck & Jeon, 2019](https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00102/full), [Schramm & Rouder, 2019](https://psyarxiv.com/9ksa6/). Some researchers do both and only consider the effects significant if both models produced a significant outcome, e.g., [Brysbaert & Stevens, 2018](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6646942/).

Let's try out both.

## Option 1: Transform

```{r}
boxcox(m1)
```

The Box-Cox test suggests that we need an inverse transformation.

```{r}
# Add a new column transRT with inverse RTs:
dataCorr3 <- dataCorr2 %>%
  mutate(transRT = -10000/RT)
# Check:
plot(density(dataCorr3$transRT))
qqnorm(dataCorr3$transRT) 
# Fit a model on inverse RTs and check residuals:
mInv <- lm(transRT ~ Cond, data = dataCorr3)
hist(residuals(mInv))
qqPlot(residuals(mInv))
```

## Option 2: Do not transform

If we decide to continue with raw data, we will fit a generalised linear mixed effects model with a gamma distribution and identity link.

The Gamma distribution is the sum of multiple exponential distributions. Basically, it models the probability that no event occurs until a certain period of time and, therefore, several serial stages of processing, each of which finishes with a time that is exponentially distributed (see e.g., [Van Zandt & Ratcliff, 1995](https://link.springer.com/article/10.3758/BF03214411)).

In GLM and GLME models, fixed factors are treated as linear predictors of a function of the observed response rather than the observed response itself. Because we assume that RT is a direct measure of the time required to name a picture, the function binding the expected values of the DV and the effect of the predictor is the identity link. 

# Summary statistics and plots

Let's visualise the data before we fit the models.

```{r}
(RT <- summarySEwithin(dataCorr3, measurevar = "RT", withinvars = "Cond",
                       idvar = "Subj", na.rm = FALSE, conf.interval = .95))
```

## Plot all conditions

```{r}
ggplot(RT, aes(x = Cond, y = RT, fill = Cond)) +
  geom_bar(position = position_dodge(), stat = "identity",
           color = "black",
           size = .3) +
  geom_errorbar(aes(ymin = RT-se, ymax = RT+se),
                size = .3, width = .2,
                position = position_dodge(.9)) +
  xlab("Distractor condition") +
  ylab("Response time (ms)") +
  coord_cartesian(ylim = c(500,900)) +
  theme_classic() +
  theme(axis.title.x = element_text(size = rel(1.2), colour = "black"),
        axis.title.y = element_text(size = rel(1.2), colour = "black"),
        panel.background = element_rect(colour = "white"),
        axis.text = element_text(size = rel(1), colour = "black"),
        legend.text = element_text(size = rel(1), colour = "black"),
        legend.title = element_text(size = rel(1.2), colour = "black"),
        axis.line = element_line(colour = "black")) +
     scale_fill_manual(name = "Distractor condition", 
                     labels = c("Unknown pseudoword", "German sem. related", "German sem. unrelated"), 
                     values = c("#D95F02", "#440154FF", "#35B779FF")) + guides(fill = FALSE) +
  scale_x_discrete(labels = c("Unknown pseudoword", "German sem. related", "German sem. unrelated"))
```

## Plot contrast 1 (related vs. unrelated)

```{r}
dataG <- dataCorr3 %>%
  filter(Cond == "SemRelG" | Cond == "SemUnRelG")
dataG$Cond <- factor(dataG$Cond)

RT1 <- summarySEwithin(dataG, measurevar = "RT", withinvars = "Cond",
                       idvar = "Subj", na.rm = FALSE, conf.interval = .95)

ggplot(RT1, aes(x = Cond, y = RT, fill = Cond)) +
  geom_bar(position = position_dodge(), stat = "identity",
           color = "black", 
           size = .3) +
  geom_errorbar(aes(ymin = RT-se, ymax = RT+se),
                size = .3, width = .2,
                position = position_dodge(.9)) +
  xlab("Distractor condition") +
  ylab("Response time (ms)") +
  coord_cartesian(ylim = c(500,950)) +
  theme_classic() +
  theme(axis.title.x = element_text(size = rel(1.2), colour = "black"),
        axis.title.y = element_text(size = rel(1.2), colour = "black"),
        panel.background = element_rect(colour = "white"),
        axis.text = element_text(size = rel(1), colour = "black"),
        legend.text = element_text(size = rel(1), colour = "black"),
        legend.title = element_text(size = rel(1.2), colour = "black"),
        axis.line = element_line(colour = "black")) +
      scale_fill_manual(name = "Distractor condition", 
                     labels = c("German sem. related", "German sem. unrelated"), 
                     values = c("#440154FF", "#35B779FF")) + guides(fill = FALSE) +
  scale_x_discrete(labels = c("German sem. related", "German sem. unrelated"))
```

## Plot contrast 2 (unknown vs. unrelated)

```{r}
dataGU <- dataCorr3 %>%
  filter(Cond == "SemUnRelG" | Cond == "Baseline")

RT2 <- summarySEwithin(dataGU, measurevar = "RT", withinvars = "Cond",
                       idvar = "Subj", na.rm = FALSE, conf.interval = .95)

ggplot(RT2, aes(x = Cond, y = RT, fill = Cond)) +
  geom_bar(position = position_dodge(), stat = "identity",
           color = "black",
           size = .3) +
  geom_errorbar(aes(ymin = RT-se, ymax = RT+se),
                size = .3, width = .2,
                position = position_dodge(.9)) +
  xlab("Distractor condition") +
  ylab("Response time (ms)") +
  coord_cartesian(ylim = c(500,900)) +
  theme_classic() +
  theme(axis.title.x = element_text(size = rel(1.2), colour = "black"),
        axis.title.y = element_text(size = rel(1.2), colour = "black"),
        panel.background = element_rect(colour = "white"),
        axis.text = element_text(size = rel(1), colour = "black"),
        legend.text = element_text(size = rel(1), colour = "black"),
        legend.title = element_text(size = rel(1.2), colour = "black"),
        axis.line = element_line(colour = "black")) +
     scale_fill_manual(name = "Distractor condition", 
                     labels = c("Unknown pseudoword", "German sem. unrelated"), 
                     values = c("#D95F02", "#35B779FF")) + guides(fill = FALSE) +
  scale_x_discrete(labels = c("Unknown pseudoword","German sem. unrelated"))
```

# Fit the model

[Barr et al., 2013](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/) have recommended to fit models with a maximal random effect structure, and many researchers do so. However, this often leads to overparametrisation such that resulting models are two complex and uninterpretable. An alternative approach would be to fit a model that **is** supported by the data [Bates et al., 2015](https://arxiv.org/abs/1506.04967).

## Option 1 (transformed RTs)

We start by fitting a model with a maximal structure and then simplify it using the Principled Component Analysis (PCA) of the random effects structure to determine the number of variance components and correlation parameters supported by the data.

What is a maximal model?

*Random effects for subjects:*

  - the by-subjects adjustment to the grand mean 
  - the by-subjects adjustment to the mean slope
 
*Random effects for items:*

  - the by-subjects adjustment to the grand mean 
  - the by-subjects adjustment to the mean slope

And the *residual error*.

Mathematically, it looks like this:

$$
RT \sim \beta_0 + u_0 + w_0 + (\beta_1 + u_1 + w_1)*Cond + \varepsilon
$$

where 

- $\beta_0$ is the intercept parameter

- $\beta_1$ is the the slope parameter

- $\varepsilon$ is the residual

- `Cond` is the effect of Condition

and the variance components are
 
- $u_0$: adjustment to the intercept by subjects

- $w_0$: adjustment to the intercept by items

- $u_1$: adjustment to the slope by subjects

- $w_1$: adjustment to the slope by items
  
with the correlations between the adjustments for the intercepts and slopes expressed in the following matrices

\[
\left( 
\begin{array}{cc}
u_0 \\ 
u_1 
\end{array} 
\right) \sim \left(Normal _2\left(
\begin{array} {cc}
0 \\
0
\end{array}
\right), \left[
\begin{array}{cc}
\sigma u_0^2 & \rho \sigma u_0\sigma u_1 \\ 
\rho \sigma u_0\sigma u_1 & \sigma u_1^2
\end{array}
\right]
\right)
\]

\[
\left( 
\begin{array}{cc}
w_0 \\ 
w_1 
\end{array} 
\right) \sim \left(Normal _2\left(
\begin{array} {cc}
0 \\
0
\end{array}
\right), \left[
\begin{array}{cc}
\sigma w_0^2 & \rho \sigma w_0\sigma w_1 \\ 
\rho \sigma w_0\sigma w_1 & \sigma w_1^2
\end{array}
\right]
\right)
\]

where

$\rho$ is the correlation parameter.
  
